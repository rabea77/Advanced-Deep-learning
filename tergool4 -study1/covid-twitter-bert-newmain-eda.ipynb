{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-11T13:25:37.654842Z",
     "iopub.status.busy": "2025-08-11T13:25:37.654283Z",
     "iopub.status.idle": "2025-08-11T13:25:53.631664Z",
     "shell.execute_reply": "2025-08-11T13:25:53.631060Z",
     "shell.execute_reply.started": "2025-08-11T13:25:37.654797Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdiab55\u001b[0m (\u001b[33mdiab55-tel-aviv-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "wandb.login(key=\"d12da696b882ebdf6b786d182d46febc1a77dcdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T13:26:02.206424Z",
     "iopub.status.busy": "2025-08-11T13:26:02.205421Z",
     "iopub.status.idle": "2025-08-11T13:26:02.710819Z",
     "shell.execute_reply": "2025-08-11T13:26:02.710141Z",
     "shell.execute_reply.started": "2025-08-11T13:26:02.206395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 → Extremely Negative\n",
      "1 → Extremely Positive\n",
      "2 → Negative\n",
      "3 → Neutral\n",
      "4 → Positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib  # לשמירת ה-LabelEncoder (אופציונלי)\n",
    "\n",
    "# --- טעינת הדאטה ---\n",
    "df = pd.read_csv(\"/kaggle/input/123444/processed_train.csv\")\n",
    "\n",
    "# שינוי שם עמודת הטקסט\n",
    "df = df.rename(columns={'fully_clean_text': 'Tweet'})\n",
    "\n",
    "# קידוד התוויות ממחרוזות למספרים\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['Sentiment'])\n",
    "\n",
    "# שמירת המיפוי לשימוש עתידי (אופציונלי)\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "# הצגת המיפוי\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i} → {label}\")\n",
    "\n",
    "# --- חלוקה ל-Train / Eval / Test ---\n",
    "train_df, eval_df = train_test_split(\n",
    "    df[['Tweet', 'label']],          # keep only what the model needs\n",
    "    test_size=0.2,                   # 80/20 split; change if you like\n",
    "    random_state=42,\n",
    "    stratify=df['label']             # keep class balance\n",
    ")\n",
    "\n",
    "\n",
    "# שמירה של רק העמודות הדרושות למודל\n",
    "train_df = train_df[['Tweet', 'label']]\n",
    "eval_df = eval_df[['Tweet', 'label']]\n",
    "\n",
    "# שמירת קבצים\n",
    "train_df.to_csv(\"train_data.csv\", index=False)\n",
    "eval_df.to_csv(\"eval_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T13:26:09.758509Z",
     "iopub.status.busy": "2025-08-11T13:26:09.757767Z",
     "iopub.status.idle": "2025-08-11T13:26:44.761195Z",
     "shell.execute_reply": "2025-08-11T13:26:44.760422Z",
     "shell.execute_reply.started": "2025-08-11T13:26:09.758474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9606028d74459e96559bbd3b87faa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/421 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0bea091aba43b49560e89bf6869565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-11 13:26:22.754230: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754918782.930123      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754918782.984850      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f5712461ea4520b44ea12b4980004a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed1e9968010406084a2b19a373fce79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 1024)\n",
      "      (token_type_embeddings): Embedding(2, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=1024, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# שם המודל\n",
    "model_name = \"digitalepidemiologylab/covid-twitter-bert\"\n",
    "\n",
    "# טעינת הטוקנייזר\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# טעינת המודל עם מספר התוויות שלך\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=5,  # לשנות בהתאם לסט\n",
    "    ignore_mismatched_sizes=True  # רק אם הראש הותאם מחדש\n",
    ").to(device)\n",
    "\n",
    "# הצגת מבנה המודל\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T13:26:53.931714Z",
     "iopub.status.busy": "2025-08-11T13:26:53.930492Z",
     "iopub.status.idle": "2025-08-11T13:26:53.938134Z",
     "shell.execute_reply": "2025-08-11T13:26:53.937466Z",
     "shell.execute_reply.started": "2025-08-11T13:26:53.931681Z"
    }
   },
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=160):\n",
    "        self.texts = dataframe['Tweet'].fillna(\"\").astype(str).tolist()\n",
    "        self.labels = dataframe['label'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx].strip()\n",
    "        if not text:\n",
    "            text = \"[PAD]\"  # גיבוי לטקסט ריק\n",
    "\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        item = {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        # חלק מהמודלים (BERT) מחזירים token_type_ids וחלק לא (RoBERTa)\n",
    "        if \"token_type_ids\" in enc:\n",
    "            item[\"token_type_ids\"] = enc[\"token_type_ids\"].squeeze(0)\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T13:26:57.941749Z",
     "iopub.status.busy": "2025-08-11T13:26:57.940819Z",
     "iopub.status.idle": "2025-08-11T13:26:57.946499Z",
     "shell.execute_reply": "2025-08-11T13:26:57.945688Z",
     "shell.execute_reply.started": "2025-08-11T13:26:57.941698Z"
    }
   },
   "outputs": [],
   "source": [
    "def early_stop_check_acc(patience, best_acc, best_acc_epoch, current_acc, current_epoch):\n",
    "    \"\"\"\n",
    "    עצירה מוקדמת לפי Val Accuracy בלבד.\n",
    "    מחזיר: best_acc, best_acc_epoch, early_stop_flag\n",
    "    \"\"\"\n",
    "    early_stop_flag = False\n",
    "    if current_acc > best_acc:\n",
    "        best_acc = current_acc\n",
    "        best_acc_epoch = current_epoch\n",
    "    elif current_epoch - best_acc_epoch > patience:\n",
    "        early_stop_flag = True\n",
    "    return best_acc, best_acc_epoch, early_stop_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T13:27:01.991188Z",
     "iopub.status.busy": "2025-08-11T13:27:01.990898Z",
     "iopub.status.idle": "2025-08-11T13:27:02.002285Z",
     "shell.execute_reply": "2025-08-11T13:27:02.001522Z",
     "shell.execute_reply.started": "2025-08-11T13:27:01.991166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0 1 2 3 4]\n",
      "Class weights: [1.49848801 1.2401726  0.82850966 1.07523382 0.71978462]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# חישוב משקלי תוויות לפי הופעה בפועל — על ה-TRAIN בלבד\n",
    "train_labels = train_df['label'].values\n",
    "classes = np.unique(train_labels)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=train_labels\n",
    ")\n",
    "\n",
    "# הפיכה לטנסור לשימוש בתוך CrossEntropyLoss\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float, device=device)\n",
    "\n",
    "# פונקציית הפסד עם משקלים\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# אופציונלי: להדפיס כדי לדעת מה קיבלת\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T13:27:13.887454Z",
     "iopub.status.busy": "2025-08-11T13:27:13.887147Z",
     "iopub.status.idle": "2025-08-11T13:27:13.899256Z",
     "shell.execute_reply": "2025-08-11T13:27:13.898550Z",
     "shell.execute_reply.started": "2025-08-11T13:27:13.887432Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs, patience, trial):\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_accuracy_epoch = 0\n",
    "    early_stop_flag = False\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ===== Training =====\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total_train_samples = 0\n",
    "        correct_train_predictions = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * input_ids.size(0)\n",
    "            total_train_samples += input_ids.size(0)\n",
    "            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        train_loss /= total_train_samples\n",
    "        train_accuracy = correct_train_predictions / total_train_samples\n",
    "\n",
    "        # ===== Validation =====\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_val_samples = 0\n",
    "        correct_val_predictions = 0\n",
    "        all_val_labels, all_val_preds = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "                val_loss += loss.item() * input_ids.size(0)\n",
    "                total_val_samples += input_ids.size(0)\n",
    "                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        val_loss /= total_val_samples\n",
    "        val_accuracy = correct_val_predictions / total_val_samples\n",
    "\n",
    "        # מטריקות נוספות (לא על עצירה)\n",
    "        val_precision = precision_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
    "        val_recall    = recall_score(all_val_labels, all_val_preds,   average='weighted', zero_division=0)\n",
    "        val_f1        = f1_score(all_val_labels, all_val_preds,       average='weighted', zero_division=0)\n",
    "\n",
    "        # === Early Stopping לפי Accuracy ===\n",
    "        prev_best = best_val_accuracy\n",
    "        best_val_accuracy, best_val_accuracy_epoch, early_stop_flag = early_stop_check_acc(\n",
    "            patience, best_val_accuracy, best_val_accuracy_epoch, val_accuracy, epoch\n",
    "        )\n",
    "        if best_val_accuracy > prev_best:\n",
    "            # שומרים את מצב המודל הטוב ביותר עד כה\n",
    "            best_model_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Train Accuracy\": train_accuracy,\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": val_accuracy,\n",
    "            \"Validation Precision\": val_precision,\n",
    "            \"Validation Recall\": val_recall,\n",
    "            \"Validation F1\": val_f1\n",
    "        })\n",
    "\n",
    "        if early_stop_flag:\n",
    "            print(f\"Early stopping at epoch {epoch} (best Accuracy={best_val_accuracy:.4f} @ epoch {best_val_accuracy_epoch})\")\n",
    "            break\n",
    "\n",
    "    # טעינת המודל הטוב ביותר ושמירתו\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        torch.save(model.state_dict(), f\"best_model_trial_{trial.number}.pt\")\n",
    "\n",
    "    return best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T13:27:18.520662Z",
     "iopub.status.busy": "2025-08-11T13:27:18.520365Z",
     "iopub.status.idle": "2025-08-11T13:27:18.529540Z",
     "shell.execute_reply": "2025-08-11T13:27:18.528941Z",
     "shell.execute_reply.started": "2025-08-11T13:27:18.520636Z"
    }
   },
   "outputs": [],
   "source": [
    "# Objective Function for Optuna (maximize Validation Accuracy)\n",
    "def objective(trial):\n",
    "    # === Hyperparameter suggestions ===\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-5, 5e-4, log=True)\n",
    "    weight_decay  = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    patience      = trial.suggest_int(\"patience\", 2, 4)\n",
    "    batch_size    = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    num_layers    = trial.suggest_int(\"num_layers\", 2, 4)  # מספר שכבות להפשיר\n",
    "\n",
    "    # === Tokenizer and Dataset ===\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\")\n",
    "    train_dataset = TweetDataset(train_df, tokenizer)  # max_length ברירת מחדל מהמחלקה\n",
    "    val_dataset   = TweetDataset(eval_df,  tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # === Load CT-BERT Model ===\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"digitalepidemiologylab/covid-twitter-bert\", num_labels=5\n",
    "    ).to(device)\n",
    "\n",
    "    # === Freeze all layers first ===\n",
    "    for p in model.bert.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # === Unfreeze the last `num_layers` encoder blocks ===\n",
    "    for p in model.bert.encoder.layer[-num_layers:].parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # === Unfreeze the classification head ===\n",
    "    for p in model.classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # === Define loss with class weights (computed from TRAIN ONLY) ===\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    import numpy as np\n",
    "    train_labels = train_df['label'].values\n",
    "    classes = np.unique(train_labels)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_labels)\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float, device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    # === Optimizer (Adam) — only trainable params ===\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(trainable_params, lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # === Initialize W&B for tracking ===\n",
    "    wandb.init(\n",
    "        project=\"ctbert-project-2nd-run\",\n",
    "        config={\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"patience\": patience,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"architecture\": \"CT-BERT\",\n",
    "            \"dataset\": \"covid-tweets\",\n",
    "            \"early_stop_metric\": \"val_accuracy\"\n",
    "        },\n",
    "        name=f\"trial_{trial.number}\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    # === Train and evaluate (returns best Validation Accuracy) ===\n",
    "    best_val_accuracy = train_model_with_hyperparams(\n",
    "        model, train_loader, val_loader, optimizer, criterion,\n",
    "        epochs=10, patience=patience, trial=trial\n",
    "    )\n",
    "\n",
    "    wandb.finish()\n",
    "    return best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-11T13:27:23.059934Z",
     "iopub.status.busy": "2025-08-11T13:27:23.059166Z",
     "iopub.status.idle": "2025-08-11T22:07:34.763645Z",
     "shell.execute_reply": "2025-08-11T22:07:34.762767Z",
     "shell.execute_reply.started": "2025-08-11T13:27:23.059909Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 13:27:23,061] A new study created in memory with name: CTBERT_Accuracy_Study\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_132726-z3g053b3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/z3g053b3' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/z3g053b3' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/z3g053b3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▄▄▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▅▄▆▅▆▆██</td></tr><tr><td>Validation F1</td><td>▁▃▅▄▇▅▆▇█▇</td></tr><tr><td>Validation Loss</td><td>█▅▃▄▂▂▁▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▃▅▄▇▆▇▇██</td></tr><tr><td>Validation Recall</td><td>▁▃▅▄▆▅▆▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.64643</td></tr><tr><td>Train Loss</td><td>0.79664</td></tr><tr><td>Validation Accuracy</td><td>0.61106</td></tr><tr><td>Validation F1</td><td>0.6009</td></tr><tr><td>Validation Loss</td><td>0.88822</td></tr><tr><td>Validation Precision</td><td>0.6105</td></tr><tr><td>Validation Recall</td><td>0.61106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/z3g053b3' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/z3g053b3</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250811_132726-z3g053b3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 15:05:58,324] Trial 0 finished with value: 0.6178762786166585 and parameters: {'learning_rate': 0.00010549257415300259, 'weight_decay': 0.0054956360048080055, 'patience': 2, 'batch_size': 128, 'num_layers': 2}. Best is trial 0 with value: 0.6178762786166585.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_150602-mfiaav6h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/mfiaav6h' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/mfiaav6h' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/mfiaav6h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▃▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▇▇█▇▇███</td></tr><tr><td>Validation F1</td><td>▁▅▇▇█▇▇███</td></tr><tr><td>Validation Loss</td><td>█▄▃▂▂▂▂▁▁▁</td></tr><tr><td>Validation Precision</td><td>▁▆▇▇██▇███</td></tr><tr><td>Validation Recall</td><td>▁▅▇▇█▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.68975</td></tr><tr><td>Train Loss</td><td>0.72681</td></tr><tr><td>Validation Accuracy</td><td>0.63955</td></tr><tr><td>Validation F1</td><td>0.63217</td></tr><tr><td>Validation Loss</td><td>0.87094</td></tr><tr><td>Validation Precision</td><td>0.64072</td></tr><tr><td>Validation Recall</td><td>0.63955</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/mfiaav6h' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/mfiaav6h</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250811_150602-mfiaav6h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 16:58:26,164] Trial 1 finished with value: 0.6395518753044326 and parameters: {'learning_rate': 0.0004378631158079637, 'weight_decay': 0.0006020576704235517, 'patience': 4, 'batch_size': 32, 'num_layers': 4}. Best is trial 1 with value: 0.6395518753044326.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_165829-7ylkbxpx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/7ylkbxpx' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/7ylkbxpx' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/7ylkbxpx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▄▅▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▂▅▆▆▄████</td></tr><tr><td>Validation F1</td><td>▁▂▅▆▆▄████</td></tr><tr><td>Validation Loss</td><td>█▅▂▃▂▄▃▁▂▂</td></tr><tr><td>Validation Precision</td><td>▁▂▅▆▆▅█▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▂▅▆▆▄████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.83424</td></tr><tr><td>Train Loss</td><td>0.41193</td></tr><tr><td>Validation Accuracy</td><td>0.71627</td></tr><tr><td>Validation F1</td><td>0.716</td></tr><tr><td>Validation Loss</td><td>0.76451</td></tr><tr><td>Validation Precision</td><td>0.71972</td></tr><tr><td>Validation Recall</td><td>0.71627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/7ylkbxpx' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/7ylkbxpx</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250811_165829-7ylkbxpx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 18:44:17,787] Trial 2 finished with value: 0.7162688748173405 and parameters: {'learning_rate': 8.738156512522717e-05, 'weight_decay': 0.0009944317276910349, 'patience': 3, 'batch_size': 32, 'num_layers': 3}. Best is trial 2 with value: 0.7162688748173405.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_184420-6snijrbv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/6snijrbv' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/6snijrbv' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/6snijrbv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▁▆▅▆▇▅▇█</td></tr><tr><td>Validation F1</td><td>▂▄▁▆▆▇▇▆▇█</td></tr><tr><td>Validation Loss</td><td>█▆▆▅▅▄▂▃▂▁</td></tr><tr><td>Validation Precision</td><td>▁▄▃▇▆▆▇▆▇█</td></tr><tr><td>Validation Recall</td><td>▁▃▁▆▅▆▇▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.7085</td></tr><tr><td>Train Loss</td><td>0.67297</td></tr><tr><td>Validation Accuracy</td><td>0.66318</td></tr><tr><td>Validation F1</td><td>0.65964</td></tr><tr><td>Validation Loss</td><td>0.783</td></tr><tr><td>Validation Precision</td><td>0.66389</td></tr><tr><td>Validation Recall</td><td>0.66318</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/6snijrbv' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/6snijrbv</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250811_184420-6snijrbv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 20:29:03,360] Trial 3 finished with value: 0.6631758402338042 and parameters: {'learning_rate': 0.00022177393596707737, 'weight_decay': 0.002801550385827614, 'patience': 2, 'batch_size': 128, 'num_layers': 3}. Best is trial 2 with value: 0.7162688748173405.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250811_202906-bt9iaq25</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/bt9iaq25' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/bt9iaq25' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/bt9iaq25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇▇█</td></tr><tr><td>Train Loss</td><td>█▅▄▃▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▆▅▆▅▂▇███</td></tr><tr><td>Validation F1</td><td>▁▇▅▆▅▂████</td></tr><tr><td>Validation Loss</td><td>█▄▄▄▄▆▃▃▁▁</td></tr><tr><td>Validation Precision</td><td>▁▅▅▆▅▅███▇</td></tr><tr><td>Validation Recall</td><td>▁▆▅▆▅▂▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.70492</td></tr><tr><td>Train Loss</td><td>0.68484</td></tr><tr><td>Validation Accuracy</td><td>0.64661</td></tr><tr><td>Validation F1</td><td>0.6426</td></tr><tr><td>Validation Loss</td><td>0.83244</td></tr><tr><td>Validation Precision</td><td>0.64615</td></tr><tr><td>Validation Recall</td><td>0.64661</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/bt9iaq25' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run/runs/bt9iaq25</a><br> View project at: <a href='https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/diab55-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250811_202906-bt9iaq25/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-11 22:07:34,754] Trial 4 finished with value: 0.6468582562104238 and parameters: {'learning_rate': 0.0001571216817173418, 'weight_decay': 0.002123357971205705, 'patience': 2, 'batch_size': 64, 'num_layers': 2}. Best is trial 2 with value: 0.7162688748173405.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Validation Accuracy: 0.7163\n",
      "Best hyperparameters: {'learning_rate': 8.738156512522717e-05, 'weight_decay': 0.0009944317276910349, 'patience': 3, 'batch_size': 32, 'num_layers': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['optuna_ctbert_accuracy_study.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# יצירת Study של Optuna - למקסם Validation Accuracy\n",
    "study = optuna.create_study(\n",
    "    study_name=\"CTBERT_Accuracy_Study\",\n",
    "    direction=\"maximize\"\n",
    ")\n",
    "\n",
    "# הרצה של 5 ניסויים\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# הדפסת התוצאה הטובה ביותר\n",
    "print(f\"\\nBest Validation Accuracy: {study.best_value:.4f}\")\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# שמירת התוצאות (אופציונלי)\n",
    "joblib.dump(study, \"optuna_ctbert_accuracy_study.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8049672,
     "sourceId": 12734806,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
