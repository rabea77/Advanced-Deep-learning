{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score, accuracy_score\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m     14\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(device)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wandb'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import optuna\n",
    "import wandb\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "wandb.login(key=\"017a8a1cf1968e847ba05f92a8935af78befe33f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 → Extremely Negative\n",
      "1 → Extremely Positive\n",
      "2 → Negative\n",
      "3 → Neutral\n",
      "4 → Positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib  # לשמירת ה-LabelEncoder (אופציונלי)\n",
    "\n",
    "# --- טעינת הדאטה ---\n",
    "df = pd.read_csv(r\"C:\\Users\\rabea\\Desktop\\my_eda.csv\", encoding='latin1')\n",
    "\n",
    "# שינוי שם עמודת הטקסט\n",
    "df = df.rename(columns={'Tweet': 'Original'})\n",
    "df = df.rename(columns={'normalized_tweet': 'Tweet'})\n",
    "\n",
    "# קידוד התוויות ממחרוזות למספרים\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['Sentiment'])\n",
    "\n",
    "# שמירת המיפוי לשימוש עתידי (אופציונלי)\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "# הצגת המיפוי\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i} → {label}\")\n",
    "\n",
    "# --- חלוקה ל-Train / Eval /  ---\n",
    "train_df, eval_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['label']\n",
    ")\n",
    "\n",
    "\n",
    "# שמירה של רק העמודות הדרושות למודל\n",
    "train_df = train_df[['Tweet', 'label']]\n",
    "eval_df = eval_df[['Tweet', 'label']]\n",
    "\n",
    "\n",
    "# שמירת קבצים\n",
    "train_df.to_csv(\"train_data.csv\", index=False)\n",
    "eval_df.to_csv(\"eval_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# שם המודל\n",
    "model_name = \"digitalepidemiologylab/covid-twitter-bert\"\n",
    "\n",
    "# טעינת הטוקנייזר\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# טעינת המודל עם מספר התוויות שלך\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=5,  # לשנות בהתאם לסט\n",
    "    ignore_mismatched_sizes=True  # רק אם הראש הותאם מחדש\n",
    ").to(device)\n",
    "\n",
    "# הצגת מבנה המודל\n",
    "print(model)\n",
    "\n",
    "print(df['Tweet'].iloc[80])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:45:38.917851Z",
     "iopub.status.busy": "2025-08-14T10:45:38.916511Z",
     "iopub.status.idle": "2025-08-14T10:45:38.926400Z",
     "shell.execute_reply": "2025-08-14T10:45:38.925449Z",
     "shell.execute_reply.started": "2025-08-14T10:45:38.917812Z"
    }
   },
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=96):\n",
    "        self.texts = dataframe['Tweet'].fillna(\"\").astype(str).tolist()\n",
    "        self.labels = dataframe['label'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx].strip()\n",
    "        if not text:\n",
    "            text = \"[PAD]\"  # גיבוי לטקסט ריק\n",
    "\n",
    "        label = int(self.labels[idx])\n",
    "\n",
    "        enc = self.tokenizer(\n",
    "            text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        item = {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "        # חלק מהמודלים (BERT) מחזירים token_type_ids וחלק לא (RoBERTa)\n",
    "        if \"token_type_ids\" in enc:\n",
    "            item[\"token_type_ids\"] = enc[\"token_type_ids\"].squeeze(0)\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:45:43.762538Z",
     "iopub.status.busy": "2025-08-14T10:45:43.761805Z",
     "iopub.status.idle": "2025-08-14T10:45:43.766876Z",
     "shell.execute_reply": "2025-08-14T10:45:43.765828Z",
     "shell.execute_reply.started": "2025-08-14T10:45:43.762515Z"
    }
   },
   "outputs": [],
   "source": [
    "def early_stop_check_acc(patience, best_acc, best_acc_epoch, current_acc, current_epoch):\n",
    "    \"\"\"\n",
    "    עצירה מוקדמת לפי Val Accuracy בלבד.\n",
    "    מחזיר: best_acc, best_acc_epoch, early_stop_flag\n",
    "    \"\"\"\n",
    "    early_stop_flag = False\n",
    "    if current_acc > best_acc:\n",
    "        best_acc = current_acc\n",
    "        best_acc_epoch = current_epoch\n",
    "    elif current_epoch - best_acc_epoch > patience:\n",
    "        early_stop_flag = True\n",
    "    return best_acc, best_acc_epoch, early_stop_flag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:45:56.317946Z",
     "iopub.status.busy": "2025-08-14T10:45:56.317619Z",
     "iopub.status.idle": "2025-08-14T10:45:56.329686Z",
     "shell.execute_reply": "2025-08-14T10:45:56.328743Z",
     "shell.execute_reply.started": "2025-08-14T10:45:56.317923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: [0 1 2 3 4]\n",
      "Class weights: [1.49423428 1.23755402 0.8287368  1.08166195 0.71861982]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# חישוב משקלי תוויות לפי הופעה בפועל — על ה-TRAIN בלבד\n",
    "train_labels = train_df['label'].values\n",
    "classes = np.unique(train_labels)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=classes,\n",
    "    y=train_labels\n",
    ")\n",
    "\n",
    "# הפיכה לטנסור לשימוש בתוך CrossEntropyLoss\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float, device=device)\n",
    "\n",
    "# פונקציית הפסד עם משקלים\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# אופציונלי: להדפיס כדי לדעת מה קיבלת\n",
    "print(\"Classes:\", classes)\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:46:09.300953Z",
     "iopub.status.busy": "2025-08-14T10:46:09.300364Z",
     "iopub.status.idle": "2025-08-14T10:46:09.312187Z",
     "shell.execute_reply": "2025-08-14T10:46:09.311323Z",
     "shell.execute_reply.started": "2025-08-14T10:46:09.300929Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model_with_hyperparams(model, train_loader, val_loader, optimizer, criterion, epochs, patience, trial):\n",
    "    best_val_accuracy = 0.0\n",
    "    best_val_accuracy_epoch = 0\n",
    "    early_stop_flag = False\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # ===== Training =====\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        total_train_samples = 0\n",
    "        correct_train_predictions = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item() * input_ids.size(0)\n",
    "            total_train_samples += input_ids.size(0)\n",
    "            correct_train_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        train_loss /= total_train_samples\n",
    "        train_accuracy = correct_train_predictions / total_train_samples\n",
    "\n",
    "        # ===== Validation =====\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        total_val_samples = 0\n",
    "        correct_val_predictions = 0\n",
    "        all_val_labels, all_val_preds = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                loss = criterion(logits, labels)\n",
    "\n",
    "                val_loss += loss.item() * input_ids.size(0)\n",
    "                total_val_samples += input_ids.size(0)\n",
    "                correct_val_predictions += (logits.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "                all_val_labels.extend(labels.cpu().numpy())\n",
    "                all_val_preds.extend(logits.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        val_loss /= total_val_samples\n",
    "        val_accuracy = correct_val_predictions / total_val_samples\n",
    "\n",
    "        # מטריקות נוספות (לא על עצירה)\n",
    "        val_precision = precision_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
    "        val_recall    = recall_score(all_val_labels, all_val_preds,   average='weighted', zero_division=0)\n",
    "        val_f1        = f1_score(all_val_labels, all_val_preds,       average='weighted', zero_division=0)\n",
    "\n",
    "        # === Early Stopping לפי Accuracy ===\n",
    "        prev_best = best_val_accuracy\n",
    "        best_val_accuracy, best_val_accuracy_epoch, early_stop_flag = early_stop_check_acc(\n",
    "            patience, best_val_accuracy, best_val_accuracy_epoch, val_accuracy, epoch\n",
    "        )\n",
    "        if best_val_accuracy > prev_best:\n",
    "            # שומרים את מצב המודל הטוב ביותר עד כה\n",
    "            best_model_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Train Accuracy\": train_accuracy,\n",
    "            \"Validation Loss\": val_loss,\n",
    "            \"Validation Accuracy\": val_accuracy,\n",
    "            \"Validation Precision\": val_precision,\n",
    "            \"Validation Recall\": val_recall,\n",
    "            \"Validation F1\": val_f1\n",
    "        })\n",
    "\n",
    "        if early_stop_flag:\n",
    "            print(f\"Early stopping at epoch {epoch} (best Accuracy={best_val_accuracy:.4f} @ epoch {best_val_accuracy_epoch})\")\n",
    "            break\n",
    "\n",
    "    # טעינת המודל הטוב ביותר ושמירתו\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        torch.save(model.state_dict(), f\"best_model_trial_{trial.number}.pt\")\n",
    "\n",
    "    return best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:47:25.066120Z",
     "iopub.status.busy": "2025-08-14T10:47:25.065410Z",
     "iopub.status.idle": "2025-08-14T10:47:25.079056Z",
     "shell.execute_reply": "2025-08-14T10:47:25.078249Z",
     "shell.execute_reply.started": "2025-08-14T10:47:25.066077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Objective Function for Optuna (maximize Validation Accuracy)\n",
    "def objective(trial):\n",
    "    # === Hyperparameter suggestions ===\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 5e-5, 5e-4, log=True)\n",
    "    weight_decay  = trial.suggest_float(\"weight_decay\", 1e-6, 1e-2, log=True)\n",
    "    patience      = trial.suggest_int(\"patience\", 2, 4)\n",
    "    batch_size    = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    num_layers    = trial.suggest_int(\"num_layers\", 2, 4)  # מספר שכבות להפשיר\n",
    "\n",
    "    # === Tokenizer and Dataset ===\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"digitalepidemiologylab/covid-twitter-bert\")\n",
    "    train_dataset = TweetDataset(train_df, tokenizer)  # max_length ברירת מחדל מהמחלקה\n",
    "    val_dataset   = TweetDataset(eval_df,  tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # === Load CT-BERT Model ===\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        \"digitalepidemiologylab/covid-twitter-bert\", num_labels=5\n",
    "    ).to(device)\n",
    "\n",
    "    # === Freeze all layers first ===\n",
    "    for p in model.bert.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    # === Unfreeze the last `num_layers` encoder blocks ===\n",
    "    for p in model.bert.encoder.layer[-num_layers:].parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # === Unfreeze the classification head ===\n",
    "    for p in model.classifier.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "    # === Define loss with class weights (computed from TRAIN ONLY) ===\n",
    "    from sklearn.utils.class_weight import compute_class_weight\n",
    "    import numpy as np\n",
    "    train_labels = train_df['label'].values\n",
    "    classes = np.unique(train_labels)\n",
    "    class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=train_labels)\n",
    "    class_weights_tensor = torch.tensor(class_weights, dtype=torch.float, device=device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "    # === Optimizer (Adam) — only trainable params ===\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = optim.Adam(trainable_params, lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # === Initialize W&B for tracking ===\n",
    "    wandb.init(\n",
    "        project=\"ctbert-project-2nd-run\",\n",
    "        config={\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"patience\": patience,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"architecture\": \"CT-BERT\",\n",
    "            \"dataset\": \"covid-tweets\",\n",
    "            \"early_stop_metric\": \"val_accuracy\"\n",
    "        },\n",
    "        name=f\"trial_{trial.number}\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "    # === Train and evaluate (returns best Validation Accuracy) ===\n",
    "    best_val_accuracy = train_model_with_hyperparams(\n",
    "        model, train_loader, val_loader, optimizer, criterion,\n",
    "        epochs=10, patience=patience, trial=trial\n",
    "    )\n",
    "\n",
    "    wandb.finish()\n",
    "    return best_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:47:29.927706Z",
     "iopub.status.busy": "2025-08-14T10:47:29.927012Z",
     "iopub.status.idle": "2025-08-14T15:13:04.007556Z",
     "shell.execute_reply": "2025-08-14T15:13:04.006830Z",
     "shell.execute_reply.started": "2025-08-14T10:47:29.927672Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-14 10:47:29,930] A new study created in memory with name: CTBERT_Accuracy_Study\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250814_104733-b554y6ks</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/b554y6ks' target=\"_blank\">trial_0</a></strong> to <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/b554y6ks' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/b554y6ks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▅▅▇▇██▇▇█</td></tr><tr><td>Validation F1</td><td>▁▆▅▇▇██▇▇█</td></tr><tr><td>Validation Loss</td><td>▃▁▂▁▃▄▄▇▇█</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▇██▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▅▅▇▇██▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.95673</td></tr><tr><td>Train Loss</td><td>0.11071</td></tr><tr><td>Validation Accuracy</td><td>0.72598</td></tr><tr><td>Validation F1</td><td>0.72704</td></tr><tr><td>Validation Loss</td><td>1.17402</td></tr><tr><td>Validation Precision</td><td>0.7301</td></tr><tr><td>Validation Recall</td><td>0.72598</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_0</strong> at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/b554y6ks' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/b554y6ks</a><br> View project at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250814_104733-b554y6ks/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-14 11:46:50,815] Trial 0 finished with value: 0.7313615252994378 and parameters: {'learning_rate': 6.340401056296099e-05, 'weight_decay': 6.459585710110239e-06, 'patience': 4, 'batch_size': 32, 'num_layers': 4}. Best is trial 0 with value: 0.7313615252994378.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250814_114654-o8mhe7s9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/o8mhe7s9' target=\"_blank\">trial_1</a></strong> to <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/o8mhe7s9' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/o8mhe7s9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 8 (best Accuracy=0.7045 @ epoch 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▇▇██</td></tr><tr><td>Train Loss</td><td>█▆▄▃▃▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▃▆▇████</td></tr><tr><td>Validation F1</td><td>▁▃▆▇████</td></tr><tr><td>Validation Loss</td><td>▅▂▁▂▃▄██</td></tr><tr><td>Validation Precision</td><td>▁▄▆▇████</td></tr><tr><td>Validation Recall</td><td>▁▃▆▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>8</td></tr><tr><td>Train Accuracy</td><td>0.9134</td></tr><tr><td>Train Loss</td><td>0.21083</td></tr><tr><td>Validation Accuracy</td><td>0.69567</td></tr><tr><td>Validation F1</td><td>0.69516</td></tr><tr><td>Validation Loss</td><td>1.00992</td></tr><tr><td>Validation Precision</td><td>0.69755</td></tr><tr><td>Validation Recall</td><td>0.69567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_1</strong> at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/o8mhe7s9' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/o8mhe7s9</a><br> View project at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250814_114654-o8mhe7s9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-14 12:28:41,332] Trial 1 finished with value: 0.7044732339281349 and parameters: {'learning_rate': 5.4366470029815594e-05, 'weight_decay': 5.243390698983217e-06, 'patience': 2, 'batch_size': 32, 'num_layers': 2}. Best is trial 0 with value: 0.7313615252994378.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250814_122844-v2bk3hwm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/v2bk3hwm' target=\"_blank\">trial_2</a></strong> to <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/v2bk3hwm' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/v2bk3hwm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▂▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▄▆▇▇▇███</td></tr><tr><td>Validation F1</td><td>▁▅▄▆▇▇▇███</td></tr><tr><td>Validation Loss</td><td>█▄▄▂▁▁▃▁▄▄</td></tr><tr><td>Validation Precision</td><td>▁▄▄▆▇▇▇███</td></tr><tr><td>Validation Recall</td><td>▁▄▄▆▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.8504</td></tr><tr><td>Train Loss</td><td>0.36713</td></tr><tr><td>Validation Accuracy</td><td>0.71816</td></tr><tr><td>Validation F1</td><td>0.71582</td></tr><tr><td>Validation Loss</td><td>0.8017</td></tr><tr><td>Validation Precision</td><td>0.72426</td></tr><tr><td>Validation Recall</td><td>0.71816</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_2</strong> at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/v2bk3hwm' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/v2bk3hwm</a><br> View project at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250814_122844-v2bk3hwm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-14 13:22:30,742] Trial 2 finished with value: 0.72647274505011 and parameters: {'learning_rate': 0.00013253403203122914, 'weight_decay': 0.0010926603377014957, 'patience': 2, 'batch_size': 128, 'num_layers': 3}. Best is trial 0 with value: 0.7313615252994378.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250814_132233-vqfwdfc0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/vqfwdfc0' target=\"_blank\">trial_3</a></strong> to <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/vqfwdfc0' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/vqfwdfc0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▄▅▆▆▇▇▇██</td></tr><tr><td>Train Loss</td><td>█▅▄▄▃▃▂▂▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▄▅▇▆▅▇█▆</td></tr><tr><td>Validation F1</td><td>▁▃▄▅▇▇▆▇█▆</td></tr><tr><td>Validation Loss</td><td>█▅▃▃▁▁▁▁▁▃</td></tr><tr><td>Validation Precision</td><td>▁▃▄▆▇▇▆██▇</td></tr><tr><td>Validation Recall</td><td>▁▄▄▅▇▆▅▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.82285</td></tr><tr><td>Train Loss</td><td>0.43038</td></tr><tr><td>Validation Accuracy</td><td>0.70178</td></tr><tr><td>Validation F1</td><td>0.70061</td></tr><tr><td>Validation Loss</td><td>0.76092</td></tr><tr><td>Validation Precision</td><td>0.71044</td></tr><tr><td>Validation Recall</td><td>0.70178</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_3</strong> at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/vqfwdfc0' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/vqfwdfc0</a><br> View project at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250814_132233-vqfwdfc0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-14 14:17:10,393] Trial 3 finished with value: 0.7362503055487656 and parameters: {'learning_rate': 9.217205392464745e-05, 'weight_decay': 0.001433326821150192, 'patience': 3, 'batch_size': 64, 'num_layers': 3}. Best is trial 3 with value: 0.7362503055487656.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250814_141713-68nqu3kw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/68nqu3kw' target=\"_blank\">trial_4</a></strong> to <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/68nqu3kw' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/68nqu3kw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train Accuracy</td><td>▁▃▅▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▆▄▃▃▂▂▁▁▁</td></tr><tr><td>Validation Accuracy</td><td>▁▄▅▇▇██▇▇█</td></tr><tr><td>Validation F1</td><td>▁▅▅▇▇██▇▇█</td></tr><tr><td>Validation Loss</td><td>▃▁▁▁▂▄▅▅▅█</td></tr><tr><td>Validation Precision</td><td>▁▅▆▇▇▇█▇▇█</td></tr><tr><td>Validation Recall</td><td>▁▄▅▇▇██▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train Accuracy</td><td>0.94158</td></tr><tr><td>Train Loss</td><td>0.14578</td></tr><tr><td>Validation Accuracy</td><td>0.72061</td></tr><tr><td>Validation F1</td><td>0.72171</td></tr><tr><td>Validation Loss</td><td>1.05208</td></tr><tr><td>Validation Precision</td><td>0.72708</td></tr><tr><td>Validation Recall</td><td>0.72061</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trial_4</strong> at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/68nqu3kw' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run/runs/68nqu3kw</a><br> View project at: <a href='https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run' target=\"_blank\">https://wandb.ai/rabeaotman-tel-aviv-university/ctbert-project-2nd-run</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250814_141713-68nqu3kw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-14 15:13:03,999] Trial 4 finished with value: 0.7272060620875092 and parameters: {'learning_rate': 6.425278352545687e-05, 'weight_decay': 0.00014081001679032353, 'patience': 4, 'batch_size': 32, 'num_layers': 3}. Best is trial 3 with value: 0.7362503055487656.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Validation Accuracy: 0.7363\n",
      "Best hyperparameters: {'learning_rate': 9.217205392464745e-05, 'weight_decay': 0.001433326821150192, 'patience': 3, 'batch_size': 64, 'num_layers': 3}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['optuna_ctbert_accuracy_study.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# יצירת Study של Optuna - למקסם Validation Accuracy\n",
    "study = optuna.create_study(\n",
    "    study_name=\"CTBERT_Accuracy_Study\",\n",
    "    direction=\"maximize\"\n",
    ")\n",
    "\n",
    "# הרצה של 5 ניסויים\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "# הדפסת התוצאה הטובה ביותר\n",
    "print(f\"\\nBest Validation Accuracy: {study.best_value:.4f}\")\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# שמירת התוצאות (אופציונלי)\n",
    "joblib.dump(study, \"optuna_ctbert_accuracy_study.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8068425,
     "sourceId": 12763187,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
