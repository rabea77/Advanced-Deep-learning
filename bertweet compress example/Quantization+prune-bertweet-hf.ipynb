{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ad5c77-585c-4801-861a-687b3fc39c4b",
   "metadata": {},
   "source": [
    "# Compressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1177b9-ee6c-4172-a60e-008a98ad5f24",
   "metadata": {},
   "source": [
    "## 1) Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2440a72-9046-4896-9cf9-e0d052514f87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T11:33:04.229790Z",
     "iopub.status.busy": "2025-08-21T11:33:04.229507Z",
     "iopub.status.idle": "2025-08-21T11:33:04.426660Z",
     "shell.execute_reply": "2025-08-21T11:33:04.426084Z",
     "shell.execute_reply.started": "2025-08-21T11:33:04.229768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaForSequenceClassification(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-23): 24 x RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=1024, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/input/finetuned-bertweet/pytorch/default/1/finetuned_from_old\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a6dde5e-4498-4c63-9598-41f50ad57c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T11:36:58.277677Z",
     "iopub.status.busy": "2025-08-21T11:36:58.277005Z",
     "iopub.status.idle": "2025-08-21T11:36:58.284617Z",
     "shell.execute_reply": "2025-08-21T11:36:58.283747Z",
     "shell.execute_reply.started": "2025-08-21T11:36:58.277645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " non-Quantized model size: 52099072\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\" non-Quantized model size:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10dc5f4e-5266-4e19-afae-d636ac6e3799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T11:34:00.910559Z",
     "iopub.status.busy": "2025-08-21T11:34:00.910260Z",
     "iopub.status.idle": "2025-08-21T11:34:10.226402Z",
     "shell.execute_reply": "2025-08-21T11:34:10.225565Z",
     "shell.execute_reply.started": "2025-08-21T11:34:00.910536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantization complete. Model is ready for inference.\n",
      "Quantized model size: 52099072\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import quantize_dynamic\n",
    "model.eval().cpu()\n",
    "qmodel = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n",
    "model = qmodel\n",
    "\n",
    "print(\"\\nQuantization complete. Model is ready for inference.\")\n",
    "print(\"Quantized model size:\", sum(p.numel() for p in qmodel.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caa75a4c-149a-484b-b35b-1830f55199d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T11:38:39.319065Z",
     "iopub.status.busy": "2025-08-21T11:38:39.318251Z",
     "iopub.status.idle": "2025-08-21T11:39:20.437909Z",
     "shell.execute_reply": "2025-08-21T11:39:20.437270Z",
     "shell.execute_reply.started": "2025-08-21T11:38:39.319007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae824af25214f6aa03481fbca3555a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a390152b6084ef7bfeb4ff17bfe6421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519b7ceb006b4a079014de29382e3601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8bf7d82040406bb25b4ca833926e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved + zipped to: /kaggle/working/compressed_quant_dynamic.zip\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, torch, torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.ao.quantization import quantize_dynamic\n",
    "\n",
    "SAVE_DIR = \"/kaggle/working/compressed_quant_dynamic\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 1) Save quantized weights as a regular PyTorch file\n",
    "torch.save(qmodel.state_dict(), os.path.join(SAVE_DIR, \"quantized_state_dict.pt\"))\n",
    "\n",
    "# 2) Save tokenizer (for later preprocessing)\n",
    "tok = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "tok.save_pretrained(SAVE_DIR)\n",
    "\n",
    "# 3) Zip for download\n",
    "shutil.make_archive(SAVE_DIR, \"zip\", SAVE_DIR)\n",
    "print(\"Saved + zipped to:\", SAVE_DIR + \".zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645cfce5-9f43-4359-add7-33404192227a",
   "metadata": {},
   "source": [
    "## 3) Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62630180-7f04-4400-ac86-4aef8f66c5f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T11:45:11.816404Z",
     "iopub.status.busy": "2025-08-21T11:45:11.815715Z",
     "iopub.status.idle": "2025-08-21T11:45:50.624399Z",
     "shell.execute_reply": "2025-08-21T11:45:50.623723Z",
     "shell.execute_reply.started": "2025-08-21T11:45:11.816377Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pruning applied: 40% of weights zeroed out in Linear layers.\n",
      "Pruned model non-zero parameters: 355364864\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.nn.utils import prune\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/input/finetuned-bertweet/pytorch/default/1/finetuned_from_old\")\n",
    "\n",
    "\n",
    "model_to_prune = model\n",
    "parameters_to_prune = [\n",
    "    (module, 'weight')\n",
    "    for module in model_to_prune.modules() if isinstance(module, nn.Linear)]\n",
    "\n",
    "prune.global_unstructured(\n",
    "    parameters_to_prune,\n",
    "    pruning_method=prune.L1Unstructured,\n",
    "    amount=0.4)\n",
    "\n",
    "print(\"\\nPruning applied: 40% of weights zeroed out in Linear layers.\")\n",
    "print(\"Pruned model non-zero parameters:\", sum((p != 0).sum().item() for p in model_to_prune.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "524075b7-55e1-4c81-b44e-1b8d99107fc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T11:46:37.095532Z",
     "iopub.status.busy": "2025-08-21T11:46:37.095218Z",
     "iopub.status.idle": "2025-08-21T11:47:16.515628Z",
     "shell.execute_reply": "2025-08-21T11:47:16.514775Z",
     "shell.execute_reply.started": "2025-08-21T11:46:37.095510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved + zipped to: /kaggle/working/compressed_prune.zip\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, torch, torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.ao.quantization import quantize_dynamic\n",
    "\n",
    "SAVE_DIR = \"/kaggle/working/compressed_prune\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# 1) Save quantized weights as a regular PyTorch file\n",
    "torch.save(qmodel.state_dict(), os.path.join(SAVE_DIR, \"pruned_state_dict.pt\"))\n",
    "\n",
    "# 2) Save tokenizer (for later preprocessing)\n",
    "tok = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "tok.save_pretrained(SAVE_DIR)\n",
    "\n",
    "# 3) Zip for download\n",
    "shutil.make_archive(SAVE_DIR, \"zip\", SAVE_DIR)\n",
    "print(\"Saved + zipped to:\", SAVE_DIR + \".zip\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c42f4-aed0-46fb-931a-ded28ddbeffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8085117,
     "sourceId": 12788188,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 431072,
     "modelInstanceId": 413334,
     "sourceId": 528345,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 432604,
     "modelInstanceId": 414844,
     "sourceId": 530303,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
