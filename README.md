# Advanced-Deep-learning

**attention: in our work we have divided almsot everything, we have 2 separate files for each finetune (the first and last train) method per model, so each model has his own 4 files (pre compression).  

1) Main-first-Eda.ipynb, is our intial EDA, we changed things and we also tried to infer how the data distrbutes and tried to gain additional information to use

2) tergool4-study 1, contains first try of training both Bertweet and covid-tweet-bert on Main-first-Eda.ipynb data

3) tergool4-study 2, contains our second train attempt where we had 2 seperate edas for each model. In addition to that theres a file (exc4-finetune) for the finetune proccess,  

4) Final-Eda, contains our last eda adjusment that we also used in the training process of HF, we also tried to train the models via the tergool4 way but we failed to improve the ct-bert but bertweet was better.

5) the best models from tergool4, heres the pre-fintune bertweet model zip file: https://drive.google.com/drive/u/0/folders/1bod4BJpN8wlr1LBZRBw0HVeYZjZ0tVXj, pre-finetune covid-tweet-bert model: https://drive.google.com/drive/u/0/folders/1p2zUG1Wu_ggxicqMQ3Jc5CD3tBdIWDLA
heres the bertweet finetuned model zip file : https://drive.google.com/drive/u/0/folders/1f73VK6YFEotf7Z2_QBp5uoPdWpsbGQgA , covid-tweet-bert finetuned model: https://drive.google.com/drive/u/0/folders/1aZV5rGAct8kruF-sba19kkhBO4brr6HD .

6) HF contains 2 files for each model where in on of them we trained and the other we finetuned via the HF method

7) the best models from HF, heres the finetuned bertweet model zip file: https://drive.google.com/drive/u/0/folders/1prEcgV3xb0eKH7KaOU6qq4GhwAC_na2G ,  covid-tweet-bert finetuned model: 

8)ct-bert hugging face -- quantization: https://drive.google.com/drive/u/0/folders/1bydtnDb7VgMoKtAYNj3zycXr-2tsq0eS , prune: https://drive.google.com/drive/u/0/folders/1ebiL7v0mBUGth0eesjRUakykJZiQ-xyI , knowledge distill: https://drive.google.com/drive/u/0/folders/1iV9qibi7dUJlIfNFu9mn-E3IbjNS1T80

9)bertweet hugging face -- quantization: https://drive.google.com/drive/u/0/folders/1GsOxiX_RFeD7soUd0e0CWM-8e3ITIN7B , prune: https://drive.google.com/drive/u/0/folders/1YVCZM7m5yFCx3vEkCqI-RLRxqy4n1WFI , knowledge distill: https://drive.google.com/drive/u/0/folders/1w_fOZVVzuYeu-qnKaLeMrQ_DYOMr2OjU

10) bertweet - exc4 -- quantization: https://drive.google.com/drive/u/0/folders/17Nm1aQsnqal59H_Uewc9ZwIE359PgrzZ , prune: https://drive.google.com/drive/u/0/folders/1j8ZfDOQoPetHhB69-1VAw5s9eeKhg5oz , 

