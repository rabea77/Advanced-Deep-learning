# Advanced-Deep-learning

**attention: in our work we have divided almsot everything, we have 2 separate files for each finetune (the first and last train) method per model, so each model has his own 4 files (pre compression).  

1) Main-first-Eda.ipynb, is our intial EDA, we changed things and we also tried to infer how the data distrbutes and tried to gain additional information to use
2) tergool4-study 1, contains first try of training both Bertweet and covid-tweet-bert on Main-first-Eda.ipynb data
3) tergool4-study 2, contains our second train attempt where we had 2 seperate edas for each model. heres the bertweet model zip file: https://drive.google.com/drive/u/0/folders/1bod4BJpN8wlr1LBZRBw0HVeYZjZ0tVXj , covid-tweet-bert model: https://drive.google.com/drive/u/0/folders/1p2zUG1Wu_ggxicqMQ3Jc5CD3tBdIWDLA . In addition to that theres a file (exc4-finetune) for the finetune proccess,  heres the bertweet finetuned model zip file : https://drive.google.com/drive/u/0/folders/1f73VK6YFEotf7Z2_QBp5uoPdWpsbGQgA , covid-tweet-bert finetuned model: https://drive.google.com/drive/u/0/folders/1aZV5rGAct8kruF-sba19kkhBO4brr6HD ***here we had worse performance after finetune.
4) 

 
